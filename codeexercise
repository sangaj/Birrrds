# Spark code
####
weather_table = "birds.weather" 
weather = hc.read.table(weather_table)
# read data from some data source
weather_subset = (weather.where("dt > '2015-07-01 00:00:00'")
                         .where("dt < '2015-07-01 23:59:59'")).persist()
# select a subset of data ( one day data)
track_subset.withColumn('dt', F.date_format('dt', 'yyyy-MM-dd HH:mm:ss'))
# transform the time into seconds and assign it into dt
track_subset.withColumn('dt2', F.date_format('dt', 'yyyy-MM-dd HH:mm:ss')).select('dt','dt2').toPandas().head()
# change data format and assign it into dt2, then select both features and shift them into Pandas 
weather_subset.dropDuplicates(['dt'])
# drop duplicates in one column  
weatherSubset.orderBy('dt')
# sort the column
while weatherSubset.count()<86399:
    weatherSubset_dup=weatherSubset.withColumn('dt', (weatherSubset.dt.astype('timestamp') + F.expr("INTERVAL 1 SECOND")).astype('string'))
    weatherSubset=weatherSubset_dup.unionAll(weatherSubset).dropDuplicates(['dt']).orderBy('dt')
# copy the information and plus 1 seconds on the original one to extend the whole 24hours
# combine two dataframe into one and drop duplication and order it 
weatherSubset.count() # loop is terrible slow



