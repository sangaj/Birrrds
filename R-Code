

# Checking if packages needed are installed otherwise install them:
if (! require("ggmap")) {
  install.packages("ggmap")
  library(ggmap)
}
if (! require("sp")) {
  install.packages("sp")
  library(sp)
}
if (! require("rgdal")) {
  install.packages("rgdal")
  library(rgdal)
}
if (! require("rgeos")) {
  install.packages("rgeos")
  library(rgeos)
}
if (! require("ggplot2")) {
  install.packages("ggplot2")
  library(ggplot2)
}
if (! require("leaflet")) {
  install.packages("leaflet")
  library(leaflet)
}
if (! require("plyr")) {
  install.packages("plyr")
  library(plyr)
}
if (! require("dplyr")) {
  install.packages("dplyr")
  library(dplyr)
}
if (! require("magrittr")) {
  install.packages("magrittr")
  library(magrittr)
}
if (! require("readr")) {
  install.packages("readr")
  library(readr)
}
if (! require("lubridate")) {
  install.packages("lubridate")
  library(lubridate)
}
if (! require("RColorBrewer")) {
  install.packages("RColorBrewer")
  library(RColorBrewer)
}
if (! require("classInt")) {
  install.packages("classInt")
  library(classInt)
}
if (! require("scatterplot3d")) {
  install.packages("scatterplot3d")
  library(scatterplot3d)
}
if (! require("plot3D")) {
  install.packages("plot3D")
  library(plot3D)
}
if (! require("geonames")) {
  install.packages("geonames")
  library(geonames)
}
if (! require("lubridate")) {
  install.packages("lubridate")
  library(lubridate)
}
if (! require("wkb")) {
  install.packages("wkb")
  library(wkb)
}
if (! require("animation")) {
  install.packages("animation")
  library(animation)
}

if (! require("pastecs")) {
  install.packages("pastecs")
  library(animation)
}



track <- read.table("2015_12_track.csv",header=T,sep=";")
alarm <- read.table("2015_12_alarms.csv",header=T,sep=";")
ip <- read.table("2015_12_ip_metainfo.csv",header=T,sep=";")
miss <- read.table("2015_12_nearmiss.csv",header=T,sep=";")
estimate <-  read.table("2015_12_trackestimate.csv",header=T,sep=";")


tmp<- read.table("tmp100k.csv",header=T,sep=";")
tmp.a <- gsub("LINESTRING Z ","",tmp) 
tmp.a <- gsub("[()]","",tmp.a)
tmp.a <- unlist(strsplit(as.character(tmp.a), ","))
tmp.a <- unlist(strsplit(tmp.a, " "))
df <- t(matrix(tmp.a,nrow=3))
scatterplot3d(df[,1], df[,2], df[,3], highlight.3d = TRUE, col.axis = "blue",
              col.grid = "lightblue")


tmp <- read.table("tmp10k.csv",header=T,sep=";")
tmp.a <- gsub("LINESTRING Z ","",tmp$st_astext) 
tmp.a <- gsub("[()]","",tmp.a)
tmp.a <- strsplit(as.character(tmp.a), ",")
tmp.a <- lapply(tmp.a, function(x) unlist(strsplit(x, " ")))
df <-lapply(tmp.a, function(x) t(matrix(x,nrow=3)))
colnames <- c("X","Y","Z") 
for (i in seq_along(df)){
  colnames(df[[i]]) <- colnames
}
df.new <- lapply(df,function(x) subset(x,as.numeric(x[,3]) < 30))
s3d <- scatterplot3d(df.new[[1]], highlight.3d = TRUE,type="l",xlim=c(4.6,4.8),ylim=c(52.1,52.5),zlim=c(5,6),
                     col.axis = "grey",col.grid = "white")
for (i in 2:10000){
  s3d$points3d(df.new[[i]],col=i, type="l")
} 





###  kernal plot

df.new.kernal <- rbind.fill.matrix(df.new)
sp_point <- cbind(as.numeric(df.new.kernal[,1]),as.numeric(df.new.kernal[,2]))


sp_points <- SpatialPoints(coords=sp_point, proj4string=CRS("+proj=utm +zone=31 +datum=WGS84"))

grd <- Sobj_SpatialGrid(sp_points,maxDim=100)$SG
grd <- GridTopology(summary(grd)$grid[,1],cellsize=summary(grd)$grid[,2],cells.dim=summary(grd)$grid[,3])

poly <- as.points(c(min(sp_point[,1]),max(sp_point[,1]),max(sp_point[,1]),min(sp_point[,1])),c(max(sp_point[,2]),max(sp_point[,2]),min(sp_point[,2]),min(sp_point[,2])))
mserw <- mse2d(sp_point, poly=poly, nsmse=100, range=.1)
bw <- mserw$h[which.min(mserw$mse)] 

kernel1 <- spkernel2d(sp_point, poly=poly, h0=bw, grd=grd)

df <- data.frame(kernel1=kernel1)
SG <- SpatialGridDataFrame(grd, data=df)


## Plot Kernel Maps

ker.palette <- colorRampPalette(c("white", "orange","red","darkred","brown"), space = "rgb")

spplot(SG,col.regions=ker.palette(100),names.attr=c(paste("Bandwidth = ",bw, sep="", collapse="")))



## Contiguity Neighbors
W_cont_el <- poly2nb(sp_point, queen=T)
W_cont_el_mat <- nb2listw(W_cont_el, style="W", zero.policy=TRUE)
mod.sar <- lagsarlm(classification_id ~ score, data = tmp, listw=W_cont_el_mat, zero.policy=T, tol.solve=1e-12)
summary(mod.sar)

res <- mod.sar$residuals

classes_fx <- classIntervals(res, n=5, style="fixed", fixedBreaks=c(-50,-25,-5,5,25,50), rtimes = 1)
cols <- findColours(classes_fx,pal)

par(mar=rep(0,4))
plot(data,col=cols, border="grey",pretty=T)
legend(x="bottom",cex=1,fill=attr(cols,"palette"),bty="n",legend=names(attr(cols, "table")),title="Residuals from SAR Model",ncol=5)



# plot point with  google map
tmp.old <- read.table("tmp100k.csv",header=T,sep=";")
tmp.old[is.na(tmp.old)] <- 0
tmp <- tmp.old[tmp.old$classification_id != 1,]
tmp.vehicle.slow <- tmp.old[tmp.old$classification_id == 5,]
tmp.vehicle <- tmp.old[tmp.old$classification_id == 10,]
tmp.a <- gsub("LINESTRING Z ","",tmp$st_astext) 
tmp.a <- gsub("[()]","",tmp.a)
tmp.a <- strsplit(as.character(tmp.a), ",")
tmp.a <- lapply(tmp.a, function(x) unlist(strsplit(x, " ")))
df.a <-lapply(tmp.a, function(x) t(matrix(x,nrow=3)))
colnames <- c("X","Y","Z") 
for (i in seq_along(df.a)){
  colnames(df.a[[i]]) <- colnames
}
#df.new <- lapply(df.a,function(x) subset(x,as.numeric(x[,3]) < 200))
#map <- qmap("schiphol",zoom = 11, maptype = 'hybrid')

#df.new.kernal <- rbind.fill.matrix(df.new)
#sp_point <-as.data.frame(cbind(as.numeric(df.new.kernal[,1]),as.numeric(df.new.kernal[,2])))
#map + geom_point(data = sp_point, aes(x = V1, y = V2), color="#D55E00", size=1, alpha=0.5)
options(expressions=10000)
for (i in 100:500){
  sp_line.a <-as.data.frame(cbind(as.numeric(df.a[[i]][,1]),as.numeric(df.a[[i]][,2])))
  map <- map + geom_line(data = sp_line.a, aes(x = V1, y = V2), color="red", size=1, alpha=0.5)
}
print(map)



### time interval for each line
tmp.old <- read.table("tmp100k.csv",header=T,sep=";")
tmp.old[is.na(tmp.old)] <- 0
tmp.old <- tmp.old[tmp.old$classification_id != 1,]
tmp.old$timestamp_start <- ymd_hms(substr(tmp.old$timestamp_start,1,19))
tmp.old$timestamp_end <- ymd_hms(substr(tmp.old$timestamp_end,1,19))
tmp.old$interval <- as.numeric(tmp.old$timestamp_end-tmp.old$timestamp_start) ## interval from 4 to 722
hist(tmp.old$interval,breaks=100,xlim=c(0,600))



### combine estimate track with weather
estimate <-  read.table("2015_12_trackestimate.csv",header=T,sep=";")
estimate$timestamp <- ymd_hms(substr(estimate$timestamp,1,19))
weather <- read.table("2015_12_weather.csv",header=T,sep=";")
library(lubridate)
#weather$newtime <- ymd_hms(substr(weather$timestamp,1,19))
weather$timestamp <- ymd_hms(substr(weather$timestamp,1,19))
#weather <- weather[,-2]
#colnames(weather)[grepl("newtime", colnames(weather))] <- "timestamp"
weather <- weather[!duplicated(weather$timestamp),]
weather.tmp <- weather
weather.tmp$timestamp <- weather.tmp$timestamp+1
tmp <- rbind(weather,weather.tmp)
tmp <- tmp[order(tmp$timestamp),]
tmp <- tmp[!duplicated(tmp$timestamp),]
while (nrow(tmp) < 86401){
  for (i in 2:nrow(tmp))
  {if(as.numeric(difftime(tmp$timestamp[i],tmp$timestamp[i-1])) > 1)
  { 
    vector <- tmp[i-1,]
    vector$timestamp <- vector$timestamp+1
    tmp <- rbind(tmp,vector)
  } 
  }
  tmp <- tmp[order(tmp$timestamp),]
} # notice not all interval is 2seconds and some of them even no more than 1second for two records
tmp$id <- NULL
data <- join(estimate,tmp,by="timestamp") # combine two dataframe according to timestamp
data$id <- NULL
track <-  read.table("2015_12_track.csv",header=T,sep=";")
data <- join(data,track,by="id")


### plot as the time goes
estimate.plot <-  read.table("estimate100k.csv",header=T,sep=";")
estimate.plot$timestamp <- ymd_hms(substr(estimate.plot$timestamp,1,19))
estimate.plot <- estimate.plot[order(estimate.plot$timestamp),]
estimate.plot$st_astext <- gsub("POINT Z ","",estimate.plot$st_astext) 
estimate.plot$st_astext <- gsub("[()]","",estimate.plot$st_astext)
tmp.estimate <- subset(estimate.plot,select = c(timestamp,st_astext))
tmp.estimate$interval <- as.numeric(tmp.estimate$timestamp-min(tmp.estimate$timestamp))
map <- qmap("schiphol",zoom = 11, maptype = 'hybrid')
b <- as.vector(tmp.estimate$st_astext)
c <- unlist(strsplit(b,split=" "))
position <- matrix(as.numeric(c),ncol=3,byrow=T)
tmp.estimate$longitude <- position[,1]
tmp.estimate$latitude <- position[,2]
new <- tmp.estimate[,c(3:5)]
xg <- split(new,new$interval)



for (i in 1263:length(xg)) 
{
  map <- qmap("schiphol",zoom = 12, maptype = 'hybrid')
  sp_point <-as.data.frame(cbind(xg[[i]]$longitude,xg[[i]]$latitude))
  map <-  map + geom_point(data = sp_point, aes(x = V1, y = V2), color="lightblue", size=1, alpha=1)
  ggsave(paste('',i, 'plot.png', sep=""), map)
}






### relative distance
distance <-  read.table("track_full_dump.csv",header=T,sep=";")
distance[is.na(distance)] <- 0
distance1 <- subset(distance,classification_id != 1)
distance2<- gsub("LINESTRING Z ","",distance1$st_astext) 
distance.a <- gsub("[()]","",distance2)
distance.a <- strsplit(as.character(distance.a), ",")
distance.a <- lapply(distance.a, function(x) unlist(strsplit(x, " ")))
df <-lapply(distance.a, function(x) t(matrix(x,nrow=3)))
colnames <- c("X","Y","Z") 
for (i in seq_along(df)){
  colnames(df[[i]]) <- colnames
}
d <- numeric(0)

func <- function(x){
  for (i in 1:nrow(x)){
    dx <- as.numeric(x[1,1])*111.321*cos(as.numeric(x[1,2])*pi/180) - as.numeric(x[i,1])*111.321*cos(as.numeric(x[i,2])*pi/180)
    dy <- (as.numeric(x[1,2])-as.numeric(x[i,2]))*111
    d[i] <- sqrt(dx^2+dy^2)
  }
  max(d[i])
}

df.1 <- lapply(df,func)
maxdist <- min(round_any(max(head(sort(unlist(df.1)),0.99*length(unlist(df.1)))),0.1,f=ceiling),2.5)


l.lon <- 4.705
l.lat <- 52.368
r.lon <- 4.815
r.lat <- 52.283
dlon <-  4.815-4.705
dlat <-  52.368-52.368 
length0 <-  4.815*111.699 * cos(52.368 * pi/180) - 4.705*111.699 * cos(52.368 * pi/180)##??
length <- round_any(length0,0.1,f=ceiling)
width0 <-  52.368*110.574-52.283*110.574
width <- round_any(width0,0.1,f=ceiling)
### the area which team could cover
lat.det <- maxdist/111
log.det <- maxdist/(cos(52.283*pi/180)*111.321)

### observation area and grid
leftup <- c(4.705-log.det, 52.368+lat.det)
leftbo <- c(4.705-log.det, 52.283-lat.det)
rightup <- c(4.815+log.det, 52.368+lat.det)
rightbo <- c(4.815+log.det, 52.283-lat.det)

bound.x <- c(4.705-log.det,52.283-lat.det)
bound.y <- c(4.815+log.det,52.368+lat.det)
bound.matix <- data.frame(bound.x,bound.y)
n <- 10
offset <- bound.matix[,1]
size <- (bound.matix[,2]-bound.matix[,1])/n
dim <- c(n,n)
grid <- GridTopology(cellcentre.offset =  offset, cellsize = size, cells.dim = dim)






### test

library(maptools)
library(spdep)
nc_file <- system.file("shapes/sids.shp", package = "maptools")[1]
llCRS <- CRS("+proj=longlat +datum=NAD27")
nc <- readShapePoly(nc_file, ID = "FIPSNO", proj4string = llCRS)
rn <- sapply(slot(nc, "polygons"), function(x) slot(x,  "ID"))
gal_file <- system.file("etc/weights/ncCR85.gal", package = "spdep")[1]
ncCR85 <- read.gal(gal_file, region.id = rn)
nc$Observed <- nc$SID74
nc$Population <- nc$BIR74
r <- sum(nc$Observed)/sum(nc$Population)
nc$Expected <- nc$Population * r
nc$SMR <- nc$Observed/nc$Expected
library(DCluster)
eb <- empbaysmooth(nc$Observed, nc$Expected)
nc$EBPG <- eb$smthrr
ebln <- lognormalEB(nc$Observed, nc$Expected)
nc$EBLN <- exp(ebln$smthrr)
nc$EBMrshloc <- EBlocal(nc$Observed, nc$Expected, ncCR85)$est


library(gstat)
demo(pcb)



library(SpatioTemporal)
library(plotrix)
library(maps)
data(mesa.data.raw, package="SpatioTemporal")
str(mesa.data.raw,1)

sp <- cbind(x = c(0, 0, 1), y = c(0, 1, 1))
row.names(sp) <- paste("point", 1:nrow(sp), sep = "")
library("sp")
sp <- SpatialPoints(sp)
time <- as.POSIXct("2010-08-05", tz = "GMT") + 3600 * (10:13)
m <- c(10, 20, 30)
values <- rnorm(length(sp) * length(time), mean = rep(m, 4))
IDs <- paste("ID", 1:length(values), sep = "_")
mydata <- data.frame(values = signif(values, 3), ID = IDs)
library("spacetime")
stfdf <- STFDF(sp, time, data = mydata)
stfdf <- STFDF(sp, time, mydata, time + 60)
xs1 <- as(stfdf, "Spatial")
xs1
x <- as(stfdf, "STIDF")
xs2 <- as(x, "Spatial")
xs2

library("maptools")
fname <- system.file("shapes/sids.shp", package = "maptools")[1]
nc <- readShapePoly(fname, proj4string = CRS("+proj=longlat +datum=NAD27"))
nc
time <- as.POSIXct(strptime(c("1974-07-01", "1979-07-01"), "%Y-%m-%d"),tz = "GMT")
endTime <- as.POSIXct(strptime(c("1978-06-30", "1984-06-30"), "%Y-%m-%d"), tz = "GMT")
data <-  data.frame( BIR = c(nc$BIR74, nc$BIR79),NWBIR = c(nc$NWBIR74, nc$NWBIR79),SID = c(nc$SID74, nc$SID79))
nct <- STFDF(sp = as(nc, "SpatialPolygons"), time, data, endTime)

library("maptools")
fname <- system.file("shapes/sids.shp", package = "maptools")[1]
nc <- readShapePoly(fname,proj4string = CRS("+proj=longlat +datum=NAD27"))




library("maps")
states.m <- map("state", plot = FALSE, fill = TRUE)
IDs <- sapply(strsplit(states.m$names, ":"), function(x) x[1])
library("maptools")
states <- map2SpatialPolygons(states.m, IDs = IDs)
yrs <- 1970:1986
time <- as.POSIXct(paste(yrs, "-01-01", sep = ""), tz = "GMT")
library("plm")
data("Produc")
Produc.st <- STFDF(states[-8], time, Produc[order(Produc[2], Produc[1]),])
library("RColorBrewer")
stplot(Produc.st[, , "unemp"], yrs, col.regions = brewer.pal(9, "YlOrRd"),cuts = 9)
zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,data = as.data.frame(Produc.st), index = c("state", "year"))


library(data.table)
library(lfe)
library(foreign)
dta_file <- "I:/Desktop/new_testspatial.dta"
DTA <-data.table(read.dta(dta_file))
setnames(DTA, c("latitude", "longitude"), c("lat", "lon"))
m <-felm(EmpClean00 ~HDD -1 |year +FIPS |0 |lat +lon,
         data = DTA[!is.na(EmpClean00)], keepCX = TRUE)

## have a try
library(plyr)
library(dplyr)
library(plm)
library(MASS)
library(reshape2)
datatest <- read.table("I:/Desktop/gridinR.csv",header=T,sep=",")
datatest <- mutate(datatest, position=paste(datatest$x_level,datatest$y_level,sep=""))
zz <- plm(count ~ mass  + winddirectiontrue  + score,data = datatest, 
          index = c("timestep", "position"),family=poisson(link=log))
### very low R-squared


datatest <- read.table("I:/Desktop/grid_space .csv",header=T,sep=",")
data.melt <- melt(datatest,id=1)
data.melt<- data.melt[order(data.melt$timestep),]
data.melt[is.na(data.melt)] <- 0
x.easting <- 1:10
x.northing <- 1:10
Grid <- expand.grid(x.easting, x.northing)
GRID <- mutate(Grid,var=paste('X',Var1,Var2,sep=""))
N.grid <- 0:1000
GRIDNEW <- expand.grid(N.grid, GRID$var)
names(GRIDNEW) <- c("timestep","variable")
daaaata <- join(GRIDNEW, data.melt, by = c("timestep","variable"))
daaaata <- daaaata[order(daaaata$timestep),]
daaaata [is.na(daaaata)] <- 0



x.easting <- 1:10
x.northing <- 1:10
Grid <- expand.grid(x.easting, x.northing)
K <- nrow(Grid)
N <- 44641
N.all <- N * K

W <-array(0, c(K,K))
for(i in 1:K)
{
for(j in 1:K)
    {
      temp <- (Grid[i,1] - Grid[j,1])^2 + (Grid[i,2] - Grid[j,2])^2
      if(temp==1) W[i,j] <- 1
     }
}

D <-array(0, c(N,N))
for(i in 1:N)
   {
     for(j in 1:N)
       {
         if(abs((i-j))==1) D[i,j] <- 1
         }
     }
Q.W <- 0.99 * (diag(apply(W, 2, sum)) - W) + 0.01 * diag(rep(1,K))
Q.W.inv <- solve(Q.W)
phi <- mvrnorm(n=1, mu=rep(0,K), Sigma=(0.01 * Q.W.inv))
Q.D <- 0.99 * (diag(apply(D, 2, sum)) - D) + 0.01 * diag(rep(1,N))
Q.D.inv <- solve(Q.D)
delta <- mvrnorm(n=1, mu=rep(0,N), Sigma=(0.01 * Q.D.inv))
phi.long <- rep(phi, N)
delta.long <- kronecker(delta, rep(1,K))
LP <- 4 + phi.long + delta.long
mean <- exp(LP)
Y <- rpois(n=N.all, lambda=mean)

library(CARBayesST)
model <- ST.CARanova(formula=daaaata$value~1, family="poisson", W=W, interaction=FALSE,burnin=5000, n.sample=30000, thin=10)


library(spatcounts)


datatest <- read.table("I:/Desktop/grid_space .csv",header=T,sep=",")
data.melt <- melt(datatest,id=1)
data.melt<- data.melt[order(data.melt$timestep),]
data.melt[is.na(data.melt)] <- 0
temple <- cbind(sim.nmat,GRID)[,c(1,9)]
names(temple) <- c("VAR","variable")
join <- join(data.melt, temple, by="variable")
poi <- est.sc(sim.Yin, ~ sim.fm.X[,1], data.melt$VAR,model="Poi", sim.gmat, sim.nmat, totalit=10)
sim.Yin <- as.data.frame(data.melt$value)
sim.fm.X <- as.data.frame(data.melt$timestep)







#--------------------------------------------------------#
# analysis
gridspace <- read.table("I:/Desktop/grid8_space0715.csv",header=T,sep=",")
library(plyr)
library(dplyr)
grid.subset <- alply(gridspace[,-1],1)
listmatrix <- lapply(grid.subset, function(x) matrix(x,nrow=8,byrow=TRUE))
names <- c("loc22","loc23","loc24","loc25","loc26","loc27",
            "loc32","loc33","loc34","loc35","loc36","loc37",
            "loc42","loc43","loc44","loc45","loc46","loc47",
            "loc52","loc53","loc54","loc55","loc56","loc57",
            "loc62","loc63","loc64","loc65","loc66","loc67",
            "loc72","loc73","loc74","loc75","loc76","loc77")
func <- function(x) {
 mat <- matrix(unlist(x),8,8)
 w <-  which(mat==mat, arr.ind=TRUE)
 d <- as.matrix(dist(w, "maximum", diag=TRUE, upper=TRUE))
 d[d==0]=1
 a <- apply(d, 1, function(i) mat[i == 1] )
 length <- lapply(a,length) == 9
 b <- a[length]
 names(b) <- names
 b
 }
listt <-lapply(listmatrix, func)

unlistdf <- ldply(listt, function(x){
  df <- ldply(x, function(z) as.data.frame(matrix(z,ncol=9,byrow=T)))
  names(df)[1] <- "location"; 
  df
})

pretime1 <- rbind(matrix(0,ncol=9,nrow=36*1),unlistdf[c(1:(nrow(unlistdf)-36*1)),-c(1:2)])
pretime2 <- rbind(matrix(0,ncol=9,nrow=36*2),unlistdf[c(1:(nrow(unlistdf)-36*2)),-c(1:2)])
df <- cbind(unlistdf[,c(1,2,7)],pretime1,pretime2)
df <- df[order(df$location),]
colnames <- c("ts","location","Obs",
              "lt1","lm1","lb1","mt1","mm1","mb1","rt1","rm1","rb1",
              "lt2","lm2","lb2","mt2","mm2","mb2","rt2","rm2","rb2")
colnames(df) <- colnames
dframe <- filter(df,ts>2)

sample.size <- floor(0.8*nrow(dframe))
set.seed(2016)
train_id <- sample(seq_len(nrow(dframe)),size=sample.size)
train <- dframe[train_id,]
test <- dframe[-train_id,]


## glm poisson 
memory.limit(size=10000)
m1 <- glm(Obs ~ location+lt1+lm1+lb1+mt1+mm1+mb1+rt1+rm1+rb1+lt2+lm2+lb2+mt2+mm2+mb2+rt2+rm2+rb2,family="poisson", data=train)
m2 <- glm(Obs ~ lt1+lm1+lb1+mt1+mm1+mb1+rt1+rm1+rb1+lt2+lm2+lb2+mt2+mm2+mb2+rt2+rm2+rb2,family="poisson", data=train)

library(boot)
cv.glm1 <- cv.glm(train, m1, K=10)
cv.glm2 <- cv.glm(train, m2, K=10)
mse.min1 <-cv.glm1$delta[2] 
mse.min2 <-cv.glm2$delta[2] 
# with location is better

#prediction
x <- train[,c(-1,-3)]
y <- train[,3]
x1 <- train[,c(-1:-3)]

y.test <- test[,3]
x.test <- test[,c(-1,-3)]

prediction.glm <- predict(m1,x.test,type="link")
rmse.glm <- sqrt(mean((y.test-prediction.glm)^2))


library(lars)
library(MASS)
library(glmnet)
# ridge 
set.seed(2016)
x <- model.matrix(~., x)
x.test <-model.matrix(~., x.test)
cv.ridge <- cv.glmnet(x=x,y=y,family="poisson",alpha=0,nfolds=10)
minlam.ridge <- cv.ridge$lambda.min
mse.min <- cv.ridge$cvm[cv.ridge$lambda == cv.ridge$lambda.min]
#prediction error
prediction.ridge <- predict(cv.ridge,as.matrix(x.test),type="link",s="lambda.min")
rmse.ridge <- sqrt(mean((y.test-prediction.ridge)^2))
#103.75


# lasso
set.seed(2016)
cv.lasso <- cv.glmnet(x=x,y=y,family="poisson",alpha=1,nfolds=10)
minlam.lasso <- cv.lasso$lambda.min
mse.min <- cv.lasso$cvm[cv.lasso$lambda == cv.lasso$lambda.min]
#prediction error
prediction.lasso <- predict(cv.lasso,as.matrix(x.test),type="link",s="lambda.min")
rmse.lasso <- sqrt(mean((y.test-prediction.lasso)^2))
#103.72

# elastic
set.seed(2016)
cv.elastic <- cv.glmnet(x=x,y,family="poisson",alpha=0.5,nfolds=10)
minlam.elastic <- cv.elastic$lambda.min
mse.min <- cv.elastic$cvm[cv.elastic$lambda == cv.elastic$lambda.min]
#prediction error
prediction.elastic <- predict(cv.elastic,as.matrix(x.test),type="link",s="lambda.min")
rmse.elastic <- sqrt(mean((y.test-prediction.elastic)^2))
#103.72

# adaptive lasso
set.seed(2016)
betals <- solve(t(x)%*%x)%*%t(x)%*%y
cv.adapl <- cv.glmnet(x=x,y,family="poisson",alpha=0.5,nfolds=10,penalty.factor=1/abs(betals))
minlam.adapl <- cv.adapl$lambda.min
mse.min <- cv.adapl$cvm[cv.adapl$lambda == cv.adapl$lambda.min]
#prediction error
prediction.adapl <- predict(cv.adapl,as.matrix(x.test),type="link",s="lambda.min")
rmse.adapl <- sqrt(mean((y.test-prediction.adapl)^2))
#103.72

# MCP & SCAD
library(ncvreg)
set.seed(2016)
cv.mcp <- cv.ncvreg(X=x,y=y,family="poisson",penalty="MCP",nfolds=10)
minlam.mcp <- cv.mcp$lambda.min
mse.min <- min(cv.mcp$cve)
#prediction error
prediction.mcp <- predict(cv.mcp,as.matrix(x.test),type="link",lambda=minlam.mcp)
rmse.mcp <- sqrt(mean((y.test-prediction.mcp)^2))

cv.scad <- cv.ncvreg(X=x,y=y,family="poisson",penalty="SCAD",nfolds=10)
minlam.scad <- cv.scad$lambda.min
mse.min <- min(cv.scad$cve)
#prediction error
prediction.scad <- predict(cv.scad,as.matrix(x.test),type="link",lambda=minlam.scad)
rmse.scad <- sqrt(mean((y.test-prediction.scad)^2))




# no bigger difference lasso a little better








### PPT trajectory

dataPPT <- read.table("estimate_outputPPT.csv",header=T,sep=",")
dataPPT[is.na(dataPPT)] <- 0
subset0 <- subset(dataPPT, !(classification_id %in% c(0,1,5,10)))
split_subset0 <- split(subset0,subset0$track_id)
split_subset0_sub <- split_subset0[sapply(split_subset0,function(x) nrow(x)>5)]
map <- qmap("2132MH",zoom = 12, maptype='toner-lite')
options(expressions=100000)
for(i in 1:700){
  sp_line <- as.data.frame(cbind(split_subset0_sub[[i]]$position_x,
                                 split_subset0_sub[[i]]$position_y,
                                 split_subset0_sub[[i]]$classification_id
                                 ))
  map <- map + geom_line(data = sp_line,aes(x=V1,y=V2,color=V3), size=1, alpha=0.5) + scale_colour_gradientn(colours=rainbow(4))
}

print(map)






#####
#--------------------------------------------------------#
# analysis
gridspace <- read.table("I:/Desktop/grid8_space07hr.csv",header=T,sep=",")
library(plyr)
library(dplyr)
grid.subset <- alply(gridspace[,-1],1)
listmatrix <- lapply(grid.subset, function(x) matrix(x,nrow=8,byrow=TRUE))
names <- c("loc22","loc23","loc24","loc25","loc26","loc27",
            "loc32","loc33","loc34","loc35","loc36","loc37",
            "loc42","loc43","loc44","loc45","loc46","loc47",
            "loc52","loc53","loc54","loc55","loc56","loc57",
            "loc62","loc63","loc64","loc65","loc66","loc67",
            "loc72","loc73","loc74","loc75","loc76","loc77")
func <- function(x) {
 mat <- matrix(unlist(x),8,8)
 w <-  which(mat==mat, arr.ind=TRUE)
 d <- as.matrix(dist(w, "maximum", diag=TRUE, upper=TRUE))
 d[d==0]=1
 a <- apply(d, 1, function(i) mat[i == 1] )
 length <- lapply(a,length) == 9
 b <- a[length]
 names(b) <- names
 b
 }
listt <-lapply(listmatrix, func)

unlistdf <- ldply(listt, function(x){
  df <- ldply(x, function(z) as.data.frame(matrix(z,ncol=9,byrow=T)))
  names(df)[1] <- "location"; 
  df
})

pretime1 <- rbind(matrix(0,ncol=9,nrow=36*1),unlistdf[c(1:(nrow(unlistdf)-36*1)),-c(1:2)])
pretime2 <- rbind(matrix(0,ncol=9,nrow=36*2),unlistdf[c(1:(nrow(unlistdf)-36*2)),-c(1:2)])
pretime3 <- rbind(matrix(0,ncol=9,nrow=36*3),unlistdf[c(1:(nrow(unlistdf)-36*3)),-c(1:2)])
pretime4 <- rbind(matrix(0,ncol=9,nrow=36*4),unlistdf[c(1:(nrow(unlistdf)-36*4)),-c(1:2)])
pretime5 <- rbind(matrix(0,ncol=9,nrow=36*5),unlistdf[c(1:(nrow(unlistdf)-36*5)),-c(1:2)])

df <- cbind(unlistdf[,c(1,2,7)],pretime1,pretime2,pretime3,pretime4,pretime5)
df <- df[order(df$location),]
colnames <- c("ts","location","Obs",
              "lt1","lm1","lb1","mt1","mm1","mb1","rt1","rm1","rb1",
              "lt2","lm2","lb2","mt2","mm2","mb2","rt2","rm2","rb2",
              "lt3","lm3","lb3","mt3","mm3","mb3","rt3","rm3","rb3",
              "lt4","lm4","lb4","mt4","mm4","mb4","rt4","rm4","rb4",
              "lt5","lm5","lb5","mt5","mm5","mb5","rt5","rm5","rb5")
colnames(df) <- colnames
dframe <- df[!df$ts %in% c("1","2","3","4","5"),]

sample.size <- floor(0.8*max(as.numeric(dframe$ts)))
set.seed(2016)
train_id <- sample(seq_len(max(as.numeric(dframe$ts))),size=sample.size)
train <- dframe[dframe$ts %in% train_id,]
test <- dframe[!dframe$ts %in% train_id,]


## glm poisson 
memory.limit(size=20000)
m1 <- glm(Obs ~ location+lt1+lm1+lb1+mt1+mm1+mb1+rt1+rm1+rb1+lt2+lm2+lb2+mt2+mm2+mb2+rt2+rm2+rb2,family="poisson", data=train)
m2 <- glm(Obs ~ lt1+lm1+lb1+mt1+mm1+mb1+rt1+rm1+rb1+lt2+lm2+lb2+mt2+mm2+mb2+rt2+rm2+rb2,family="poisson", data=train)

library(boot)
cv.glm1 <- cv.glm(train, m1, K=10) 
cv.glm2 <- cv.glm(train, m2, K=10) 
mse.min1 <-cv.glm1$delta[2]  
mse.min2 <-cv.glm2$delta[2] 
# with location is better

#prediction
x <- train[,c(-1,-3)]
y <- train[,3]
x1 <- train[,c(-1:-3)]

y.test <- test[,3]
x.test <- test[,c(-1,-3)]

prediction.glm <- predict(m1,x.test,type="link")
rmse.glm <- sqrt(mean((y.test-prediction.glm)^2))


library(lars)
library(MASS)
library(glmnet)
# ridge 
set.seed(2016)
x <- model.matrix(~., x)
x.test <-model.matrix(~., x.test)
cv.ridge <- cv.glmnet(x=x,y=y,family="poisson",alpha=0,nfolds=10)
minlam.ridge <- cv.ridge$lambda.min
mse.min <- cv.ridge$cvm[cv.ridge$lambda == cv.ridge$lambda.min]
#prediction error
prediction.ridge <- predict(cv.ridge,as.matrix(x.test),type="link",s="lambda.min")
rmse.ridge <- sqrt(mean((y.test-prediction.ridge)^2))
#103.75


# lasso
set.seed(2016)
cv.lasso <- cv.glmnet(x=x,y=y,family="poisson",alpha=1,nfolds=10)
minlam.lasso <- cv.lasso$lambda.min
mse.min <- cv.lasso$cvm[cv.lasso$lambda == cv.lasso$lambda.min]
#prediction error
prediction.lasso <- predict(cv.lasso,as.matrix(x.test),type="link",s="lambda.min")
rmse.lasso <- sqrt(mean((y.test-prediction.lasso)^2))
mae.lasso <- mean(abs(y.test-prediction.lasso))
#103.72


# elastic
set.seed(2016)
cv.elastic <- cv.glmnet(x=x,y,family="poisson",alpha=0.5,nfolds=10)
minlam.elastic <- cv.elastic$lambda.min
mse.min <- cv.elastic$cvm[cv.elastic$lambda == cv.elastic$lambda.min]
#prediction error
prediction.elastic <- predict(cv.elastic,as.matrix(x.test),type="link",s="lambda.min")
rmse.elastic <- sqrt(mean((y.test-prediction.elastic)^2))
#103.72

# adaptive lasso
set.seed(2016)
betals <- solve(t(x)%*%x)%*%t(x)%*%y
cv.adapl <- cv.glmnet(x=x,y,family="poisson",alpha=0.5,nfolds=10,penalty.factor=1/abs(betals))
minlam.adapl <- cv.adapl$lambda.min
mse.min <- cv.adapl$cvm[cv.adapl$lambda == cv.adapl$lambda.min]
#prediction error
prediction.adapl <- predict(cv.adapl,as.matrix(x.test),type="link",s="lambda.min")
rmse.adapl <- sqrt(mean((y.test-prediction.adapl)^2))
#103.72

# MCP & SCAD
library(ncvreg)
set.seed(2016)
cv.mcp <- cv.ncvreg(X=x,y=y,family="poisson",penalty="MCP",nfolds=10)
minlam.mcp <- cv.mcp$lambda.min
mse.min <- min(cv.mcp$cve)
#prediction error
prediction.mcp <- predict(cv.mcp,as.matrix(x.test),type="link",lambda=minlam.mcp)
rmse.mcp <- sqrt(mean((y.test-prediction.mcp)^2))

cv.scad <- cv.ncvreg(X=x,y=y,family="poisson",penalty="SCAD",nfolds=10)
minlam.scad <- cv.scad$lambda.min
mse.min <- min(cv.scad$cve)
#prediction error
prediction.scad <- predict(cv.scad,as.matrix(x.test),type="link",lambda=minlam.scad)
rmse.scad <- sqrt(mean((y.test-prediction.scad)^2))
# no bigger difference lasso a little better

##arima
sample.size <- floor(0.8* as.numeric(max(dframe$ts)))
train.arima <- dframe[dframe$ts %in% c(1:sample.size),]
test.arima <- dframe[!dframe$ts %in% c(1:sample.size),]
library(glarma)
y.arima <- train.arima[,3]
X.arima <- as.matrix(train.arima[,-3])
arima <- glarma(y.arima,X.arima,thetaLags=7,type="NegBin",method="NR",residuals="Pearson",alphaInit=0)


