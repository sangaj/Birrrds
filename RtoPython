def transform(arr): 
    submatrix = []
    for i in range(0,4):
        for j in range(0,2):
            submatrix.append((arr.reshape(6,4)[i:i+3,j:j+3]).flatten())
    submatrix = np.array(submatrix)
    location = ("loc22","loc23","loc32","loc33","loc42","loc43","loc52","loc53")
    location = np.array(location)
    neighboor = np.c_[location,submatrix]
    return neighboor
    
grid_dt = grid_space.select('dt').toPandas()
grid_dt_repeat = grid_dt.apply(lambda x: np.repeat(x, 8))
grid_trans = grid_space.drop(grid_space.dt).toPandas()
transform = grid_trans.apply(lambda x: transform(x),axis=1)
submatrix = []
for i in range(0,4):
        for j in range(0,2):
            submatrix.append(grid_trans.iloc[3].reshape(6,4)[i:i+3,j:j+3].flatten())
submatrix= np.array(submatrix)
location = ("loc22","loc23","loc32","loc33","loc42","loc43","loc52","loc53")
location = np.array(location)
neighboor = np.c_[location,submatrix]
neighboor = pd.DataFrame(neighboor)
print neighboor
ttt = transform.apply(lambda x :np.array(x))
px2 = px.reshape((-1,3))
df = pd.DataFrame({'R':px2[:,0],'G':px2[:,1],'B':px2[:,2]})


neighboor = np.array(neighboor)
location = ("loc22","loc23","loc32","loc33","loc42","loc43","loc52","loc53")
location = np.array(location)
neighboor = np.c_[location,neighboor]

zdd1 = grid_dt_repeat.zipWithIndex().map(lambda (v, k): (k, v))
zdd2 = trans.zipWithIndex().map(lambda (v, k): (k , v))
combinedRDD = zdd1.join(zdd2).map(lambda x:  [x[1][0]] + x[1][1])

combinedRDD 

from pyspark.sql import Row

row = Row("val") # Or some other column name
ttt = combinedRDD.map(row).toDF()
from pyspark.sql import SQLContext
sqlContext = SQLContext(sc)
test = sqlContext.createDataFrame(combinedRDD, ['dt', 'location','lt','lm','lb','mt','mm','mb','rt','rm','rb']).collect()
combinedRDD.take(5)
print neighboor
#gs = grid_space.toPandas()
#gs.apply(transform)

   space_pandas = grid_space.toPandas().loc[0,][1:]
    time = grid_space.toPandas().loc[0,][0]
    time  = np.repeat(time , 8)
    array = space_pandas.reshape(6,4)
    neighboor = []
    for i in range(1, 5):
        for j in range(1, 3):
            neighboor.append(cell_neighbors(array, i, j))
    neighboor = np.array(neighboor)
    location = ("loc22","loc23","loc32","loc33","loc42","loc43","loc52","loc53")
    location = np.array(test)
    neighboor = np.c_[time,neighboor, test]
    
space_pandas.head(5)

print neighboor

oldColumns = attribute.schema.names
newColumns = ["location_index","dt","position_x","position_y","velocity","airspeed",
              "heading","heading_vertical","peak_mass","mass","mass_correction"]

attribute = reduce(lambda attribute, idx: attribute.withColumnRenamed(oldColumns[idx], newColumns[idx]), xrange(len(oldColumns)), attribute)
attribute = attribute.orderBy('dt','location_index').withColumn('dt', F.date_format('dt', 'yyyy-MM-dd HH:mm:ss'))


### time slot

start_time = attribute.select("dt").limit(1).toPandas().iloc[0]
start_time = start_time.get_value(start_time.index[0],'VALUE')
end_time = attribute.select("dt").sort("dt", ascending=False).limit(1).toPandas().iloc[0]
end_time = end_time.get_value(end_time.index[0],'VALUE') 
end_time = pd.Timestamp(pd.to_datetime(end_time).date() + datetime.timedelta(days=1))
days_difference = (pd.to_datetime(end_time) - pd.to_datetime(start_time)).days 
alltime = pd.date_range(start_time,end_time, freq='min', closed='left')
alltime = appdatetime = pd.DataFrame((alltime), columns=['alltime'])
for i in range(7):
    alltime = pd.concat([alltime,appdatetime],ignore_index=True)
alltime['hour'] =alltime.alltime.apply(lambda x:pd.to_datetime(x).hour)
alltime['day_index'] = alltime.hour.apply(lambda x: math.trunc(x/6)).astype('category')
alltime['tenmin'] = alltime.alltime.apply(lambda x: 
                                          x - datetime.timedelta(minutes=pd.to_datetime(x).minute 
                                                                 - math.trunc(pd.to_datetime(x).minute/10)*10))
alltime['location'] = np.repeat(["loc22","loc32","loc42","loc52","loc23","loc33","loc43","loc53"],24*60*days_difference)
