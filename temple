# remove and clean environment and history  
rm(list=ls())
gc(reset=TRUE)

# analysis for spatial features
gridspace <- read.table("spatial.csv",header=T,sep=",")
library(plyr)
library(dplyr)
library(glmnet)
library(reshape2)
library(doParallel)
library(lubridate)
registerDoParallel(4)
gridspace <- gridspace[order(gridspace$timestep),-1]
grid.subset <- alply(gridspace[,-1],1)
listmatrix <- lapply(grid.subset, function(x) matrix(x,nrow=6,byrow=TRUE))
names <- c("loc22","loc32","loc42","loc52",
           "loc23","loc33","loc43","loc53")
Names <- gridspace[,1]
func <- function(x) {
  mat <- matrix(unlist(x),6,4)
  w <-  which(mat==mat, arr.ind=TRUE)
  d <- as.matrix(dist(w, "maximum", diag=TRUE, upper=TRUE))
  d[d==0]=1
  a <- apply(d, 1, function(i) mat[i == 1] )
  length <- lapply(a,length) == 9
  b <- a[length]
  names(b) <- names
  b
}
listt <-lapply(listmatrix, func)
.id <- rep(c(1:44640),each=8)
location <- rep(c("loc22","loc32","loc42","loc52",
                  "loc23","loc33","loc43","loc53"),times=44640)

prehead <-  as.data.frame(cbind(.id,location))

unlistdf <- ldply(listt, function(x){
  df <- ldply(x, function(z) as.data.frame(matrix(z,ncol=9,byrow=T)))
  names(df)[1] <- "location"; 
  df
})

unlistdf <- join(prehead, unlistdf, by = c('.id','location'), type = "left", match = "all")
unlistdf[is.na(unlistdf)] <- 0


pretime1 <- rbind(matrix(0,ncol=9,nrow=8*1),unlistdf[c(1:(nrow(unlistdf)-8*1)),-c(1:2)])
pretime2 <- rbind(matrix(0,ncol=9,nrow=8*2),unlistdf[c(1:(nrow(unlistdf)-8*2)),-c(1:2)])
pretime3 <- rbind(matrix(0,ncol=9,nrow=8*3),unlistdf[c(1:(nrow(unlistdf)-8*3)),-c(1:2)])
pretime4 <- rbind(matrix(0,ncol=9,nrow=8*4),unlistdf[c(1:(nrow(unlistdf)-8*4)),-c(1:2)])
pretime5 <- rbind(matrix(0,ncol=9,nrow=8*5),unlistdf[c(1:(nrow(unlistdf)-8*5)),-c(1:2)])

df <- cbind(unlistdf[,c(1,2,7)],pretime1,pretime2,pretime3,pretime4,pretime5)
df <- df[order(df$location),]
colnames <- c("times","location","Obs",
              "lt1","lm1","lb1","mt1","mm1","mb1","rt1","rm1","rb1",
              "lt2","lm2","lb2","mt2","mm2","mb2","rt2","rm2","rb2",
              "lt3","lm3","lb3","mt3","mm3","mb3","rt3","rm3","rb3",
              "lt4","lm4","lb4","mt4","mm4","mb4","rt4","rm4","rb4",
              "lt5","lm5","lb5","mt5","mm5","mb5","rt5","rm5","rb5")
colnames(df) <- colnames
dframe <- df[!df$times %in% c("1","2","3","4","5"),]



sample.size <- floor(0.85*max(as.numeric(dframe$times)))
set.seed(2016)
train_id <- sample(seq_len(max(as.numeric(dframe$times))),size=sample.size)
train <- dframe[dframe$times %in% train_id,]
test <- dframe[!dframe$times %in% train_id,]

# for PPT
train <- dframe[dframe$ts %in% c(1:37719),]
#test <- dframe[dframe$ts %in% c(37720:37724),] for PPT
test <- dframe[!dframe$ts %in% c(1:37719),]


x <- train[,c(-1,-3)]
y <- train[,3]
y.test <- test[,3]
x.test <- test[,c(-1,-3)]
x <- model.matrix(~., x)
x.test <-model.matrix(~., x.test)
library(doParallel)
registerDoParallel(4)
set.seed(2016)
cv.lasso <- cv.glmnet(x=x,y=y,family="poisson",alpha=1,nfolds=5,parallel=TRUE)
prediction.lasso <- predict(cv.lasso,as.matrix(x.test),type="response",s="lambda.min")
#out <- cbind(pred=prediction.lasso,value=y.test,location=test[,2],ts=test[,1])
#write.csv(out,file="out.csv",row.names=FALSE)
mse.min <- cv.lasso$cvm[cv.lasso$lambda == cv.lasso$lambda.min]
rmse.lasso <- sqrt(mean((y.test-prediction.lasso)^2))
mae.lasso <- mean(abs(y.test-prediction.lasso))

#group lasso
group <- c(rep(1,8),rep(2,9),rep(3,9),rep(4,9),rep(5,9),rep(6,9))
cv.glasso <- cv.grpreg(X=x,y=y,family="poisso",penalty="grLasso",group,nfolds=5,parallel=TRUE,seed=2016)
prediction.glasso <- predict(cv.glasso,as.matrix(x.test),type="response")
rmse.glasso <- sqrt(mean((y.test-prediction.glasso)^2))
mae.glasso <- mean(abs(y.test-prediction.glasso))


set.seed(2016)
library(doParallel)
registerDoParallel(4)
cv.ridge <- cv.glmnet(x=x,y=y,family="poisson",alpha=0,nfolds=5,parallel=TRUE)
minlam.ridge <- cv.ridge$lambda.min
mse.min <- cv.ridge$cvm[cv.ridge$lambda == cv.ridge$lambda.min]
#prediction error
prediction.ridge <- predict(cv.ridge,as.matrix(x.test),type="response",s="lambda.min")
rmse.ridge <- sqrt(mean((y.test-prediction.ridge)^2))
mae.ridge <- mean(abs(y.test-prediction.ridge))

set.seed(2016)
library(doParallel)
registerDoParallel(4)
cv.elastic <- cv.glmnet(x=x,y,family="poisson",alpha=0.5,nfolds=5,parallel=TRUE)
minlam.elastic <- cv.elastic$lambda.min
mse.min <- cv.elastic$cvm[cv.elastic$lambda == cv.elastic$lambda.min]
#prediction error
prediction.elastic <- predict(cv.elastic,as.matrix(x.test),type="response",s="lambda.min")
rmse.elastic <- sqrt(mean((y.test-prediction.elastic)^2))
mae.elastic <- mean(abs(y.test-prediction.elastic))

set.seed(2016)
library(doParallel)
registerDoParallel(4)
betals <- solve(t(x)%*%x)%*%t(x)%*%y
cv.adapl <- cv.glmnet(x=x,y,family="poisson",alpha=0.5,nfolds=5,penalty.factor=1/abs(betals),parallel=TRUE)
minlam.adapl <- cv.adapl$lambda.min
mse.min <- cv.adapl$cvm[cv.adapl$lambda == cv.adapl$lambda.min]
#prediction error
prediction.adapl <- predict(cv.adapl,as.matrix(x.test),type="response",s="lambda.min")
out <- cbind(pred=prediction.adapl,value=y.test,location=test[,2],ts=test[,1])
write.csv(out,file="out.csv",row.names=FALSE)
rmse.adapl <- sqrt(mean((y.test-prediction.adapl)^2))
mae.adapl <- mean(abs(y.test-prediction.adapl))

library(ncvreg)
set.seed(2016)
library(doParallel)
registerDoParallel(4)
cv.mcp <- cv.ncvreg(X=x,y=y,family="poisson",penalty="MCP",nfolds=5,parallel=TRUE)
minlam.mcp <- cv.mcp$lambda.min
mse.min <- min(cv.mcp$cve)
#prediction error
prediction.mcp <- predict(cv.mcp,as.matrix(x.test),type="response",lambda=minlam.mcp)
rmse.mcp <- sqrt(mean((y.test-prediction.mcp)^2))
mae.mcp <- mean(abs(y.test-prediction.mcp))

set.seed(2016)
library(doParallel)
registerDoParallel(4)
cv.scad <- cv.ncvreg(X=x,y=y,family="poisson",penalty="SCAD",nfolds=5,parallel=TRUE)
minlam.scad <- cv.scad$lambda.min
mse.min <- min(cv.scad$cve)
#prediction error
prediction.scad <- predict(cv.scad,as.matrix(x.test),type="response",lambda=minlam.scad)
rmse.scad <- sqrt(mean((y.test-prediction.scad)^2))
mae.scad <- mean(abs(y.test-prediction.scad))


# test for random sample
sample.size <- floor(0.85*max(as.numeric(dframe$ts)))
set.seed(2016)
train_id <- sample(seq_len(max(as.numeric(dframe$ts))),size=sample.size)
train <- dframe[dframe$ts %in% train_id,]
test <- dframe[!dframe$ts %in% train_id,]
x <- train[,c(-1,-3)]
y <- train[,3]
y.test <- test[,3]
x.test <- test[,c(-1,-3)]
x <- model.matrix(~., x)
x.test <-model.matrix(~., x.test)
library(doParallel)
registerDoParallel(4)
set.seed(2016)
cv.lasso <- cv.glmnet(x=x,y=y,family="poisson",alpha=1,nfolds=5,parallel=TRUE)
prediction.lasso <- predict(cv.lasso,as.matrix(x.test),type="response",s="lambda.min")
rmse.lasso <- sqrt(mean((y.test-prediction.lasso)^2))
mae.lasso <- mean(abs(y.test-prediction.lasso))


#----------------------------------#
# all features

gridspace <- read.table("spatial.csv",header=T,sep=",")
gridspace <- gridspace[order(gridspace$timestep),-1]
timestep <- as.data.frame(c(1:44640))
names(timestep) <- "timestep"
gridspace <- join(timestep,gridspace,by="timestep",type = "left")
gridspace[is.na(gridspace)] <- 0
grid.subset <- alply(gridspace[,-1],1,.dims = TRUE)
listmatrix <- lapply(grid.subset, function(x) matrix(x,nrow=6,byrow=TRUE))
names <- c("loc22","loc32","loc42","loc52",
           "loc23","loc33","loc43","loc53")
Names <- gridspace[,1]
func <- function(x) {
  mat <- matrix(unlist(x),6,4)
  w <-  which(mat==mat, arr.ind=TRUE)
  d <- as.matrix(dist(w, "maximum", diag=TRUE, upper=TRUE))
  d[d==0]=1
  a <- apply(d, 1, function(i) mat[i == 1] )
  length <- lapply(a,length) == 9
  b <- a[length]
  names(b) <- names
  b
}
listt <-lapply(listmatrix, func)
.id <- rep(c(1:44640),each=8)
location <- rep(c("loc22","loc32","loc42","loc52",
                  "loc23","loc33","loc43","loc53"),times=44640)

prehead <-  as.data.frame(cbind(.id,location))

unlistdf <- ldply(listt, function(x){
  df <- ldply(x, function(z) as.data.frame(matrix(z,ncol=9,byrow=T)))
  names(df)[1] <- "location"; 
  df
})

unlistdf <- join(prehead, unlistdf, by = c('.id','location'), type = "left", match = "all")
unlistdf[is.na(unlistdf)] <- 0

pretime1 <- rbind(matrix(0,ncol=9,nrow=8*1),unlistdf[c(1:(nrow(unlistdf)-8*1)),-c(1:2)])
pretime2 <- rbind(matrix(0,ncol=9,nrow=8*2),unlistdf[c(1:(nrow(unlistdf)-8*2)),-c(1:2)])
pretime3 <- rbind(matrix(0,ncol=9,nrow=8*3),unlistdf[c(1:(nrow(unlistdf)-8*3)),-c(1:2)])
pretime4 <- rbind(matrix(0,ncol=9,nrow=8*4),unlistdf[c(1:(nrow(unlistdf)-8*4)),-c(1:2)])
pretime5 <- rbind(matrix(0,ncol=9,nrow=8*5),unlistdf[c(1:(nrow(unlistdf)-8*5)),-c(1:2)])

df <- cbind(unlistdf[,c(1,2,7)],pretime1,pretime2,pretime3,pretime4,pretime5)
df <- df[order(df$location),]
colnames <- c("times","location","Obs",
              "lt1","lm1","lb1","mt1","mm1","mb1","rt1","rm1","rb1",
              "lt2","lm2","lb2","mt2","mm2","mb2","rt2","rm2","rb2",
              "lt3","lm3","lb3","mt3","mm3","mb3","rt3","rm3","rb3",
              "lt4","lm4","lb4","mt4","mm4","mb4","rt4","rm4","rb4",
              "lt5","lm5","lb5","mt5","mm5","mb5","rt5","rm5","rb5")
colnames(df) <- colnames
dframe <- df[!df$times %in% c("1","2","3","4","5"),]

#attribute features#
attribute <- read.table("attribute.csv",header=T,sep=",")
attribute  <- mutate(attribute,location=paste('loc',location_index,sep=""))[,c(-1,-2,-12,-13)]
names(attribute) <- tolower(names(attribute))
aqm <- melt(attribute, id=c("timestep", "location"), na.rm=TRUE)
acast <- acast(aqm, timestep ~ location ~ variable)
attply <- alply(acast,3,.dims = TRUE)

trans <- function(mat){
  grid <- alply(mat,1,.dims=TRUE)
  gridmatrix <- lapply(grid, function(x) matrix(x,nrow=6,byrow=TRUE))
  gridmatrix <- lapply(gridmatrix,function(x) replace(x,is.na(x),0))
  
  names <- c("loc22","loc32","loc42","loc52",
             "loc23","loc33","loc43","loc53")
  func <- function(x) {
    mat <- matrix(unlist(x),6,4)
    w <-  which(mat==mat, arr.ind=TRUE)
    d <- as.matrix(dist(w, "maximum", diag=TRUE, upper=TRUE))
    d[d==0]=1
    a <- apply(d, 1, function(i) mat[i == 1] )
    length <- lapply(a,length) == 9
    b <- a[length]
    names(b) <- names
    b
  }
  listt <-lapply(gridmatrix, func)
  .id <- rep(c(1:44640),each=8)
  location <- rep(c("loc22","loc32","loc42","loc52",
                    "loc23","loc33","loc43","loc53"),times=44640)
  
  prehead <-  as.data.frame(cbind(.id,location))
  
  unlistdf <- ldply(listt, function(x){
    df <- ldply(x, function(z) as.data.frame(matrix(z,ncol=9,byrow=T)))
    names(df)[1] <- "location"; 
    df
  })
  unlistdf <- join(prehead, unlistdf, by = c('.id','location'), type = "left", match = "all")
  unlistdf[is.na(unlistdf)] <- 0
  unlistdf
}
ans <- lapply(attply,trans)
allattribute <- do.call(cbind, ans) %>% subset(select=-c(airspeed..id,airspeed.location,
                                                         heading..id,heading.location,
                                                         heading_vertical..id,heading_vertical.location,
                                                         peak_mass..id,peak_mass.location,
                                                         mass_correction..id,mass_correction.location,
                                                         position_x..id,position_x.location,
                                                         position_y..id,position_y.location))
colnames(allattribute)[which(names(allattribute) == "velocity..id")] <- "times"
colnames(allattribute)[which(names(allattribute) == "velocity.location")] <- "location"

addframe <- as.data.frame(matrix(0,ncol=72,nrow=8*1))
names(addframe) <- names(allattribute)[-c(1:2)]
pretime1.attr <- rbind(do.call("rbind", replicate(1, addframe, simplify = FALSE)),allattribute[c(1:(nrow(allattribute)-8*1)),-c(1:2)])
pretime2.attr <- rbind(do.call("rbind", replicate(2, addframe, simplify = FALSE)),allattribute[c(1:(nrow(allattribute)-8*2)),-c(1:2)])
pretime3.attr <- rbind(do.call("rbind", replicate(3, addframe, simplify = FALSE)),allattribute[c(1:(nrow(allattribute)-8*3)),-c(1:2)])
pretime4.attr <- rbind(do.call("rbind", replicate(4, addframe, simplify = FALSE)),allattribute[c(1:(nrow(allattribute)-8*4)),-c(1:2)])
pretime5.attr <- rbind(do.call("rbind", replicate(5, addframe, simplify = FALSE)),allattribute[c(1:(nrow(allattribute)-8*5)),-c(1:2)])

names(pretime1.attr) <- paste(names(addframe),'.p1',sep="")
names(pretime2.attr) <- paste(names(addframe),'.p2',sep="")
names(pretime3.attr) <- paste(names(addframe),'.p3',sep="")
names(pretime4.attr) <- paste(names(addframe),'.p4',sep="")
names(pretime5.attr) <- paste(names(addframe),'.p5',sep="")

attrall <- cbind(allattribute[,c(1,2)],pretime1.attr,pretime2.attr,pretime3.attr,pretime4.attr,pretime5.attr)


### time slot
start <- ymd_hms("2015-07-01 00:00:00")
end <- ymd_hms("2015-07-31 23:59:59")
datetime <- rep(seq(from=start, by=60, to=end),each=8)
hours <- lubridate::hour(datetime) 
ten <-cut(datetime,breaks=6*24*31) 
day.index <- as.factor(trunc(hours/6))
times <- rep(c(1:44640),each=8)
location <- rep(c("loc22","loc32","loc42","loc52",
                  "loc23","loc33","loc43","loc53"),times=44640)
Hours <- cbind.data.frame(times,hours,day.index,location,ten)


## weather
weather <- read.table("weather.csv",header=T,sep=",")
names.weather <- names(weather)
names(weather) <- names.weather[!names.weather %in% 'WTF.']
weather <- weather[,-ncol(weather)] %>% mutate(Month=as.numeric(lubridate::month(weather$DATE.LT))) %>% subset(Month==7)
weather.sub <-subset(weather,select=c("TIME.LT","VIS","CEIL","GML","X.VIS",
                                      "X.CEIL","X.GML","X.WDIR","X.WSPD","X.WGUS","X.SHWR")) 
date1 <- data.frame(do.call(rbind, strsplit(as.vector(weather$DATE.LT), split = "-"))) %>% mutate(date=ymd(paste(X3,X2,X1)))
weather.subb <- cbind.data.frame(weather.sub,ten=date1$date) %>% mutate(ten= paste(ten,TIME.LT)) 

weather.join <- join(Hours,weather.subb,by=c("ten"),type="left") %>% subset(select=-c(hours,day.index,TIME.LT))


#### all include
dframehour <- join(dframe,Hours,by=c("times","location"),type="left")
bird <- join(dframehour,weather.join,by=c("times","location"),type="left")
birds <- join(bird,attrall,by=c("times","location"),type="left")%>% subset(select=-c(ten))%>% subset(select=-c(ten))

save(birds,file="birds.Rdata")


##birds
sample.size1 <- floor(0.85*max(as.numeric(birds$times)))
set.seed(2016)
train_id1 <- sample(seq_len(max(as.numeric(birds$times))),size=sample.size1)
train1 <- birds[birds$times %in% train_id1,]
test1 <- birds[!birds$times %in% train_id1,]
x1 <- subset(train1, select=-c(times,Obs))
y1 <- as.matrix(subset(train1, select=Obs))
y1.test <- as.matrix(subset(test1, select=Obs))
x1.test <- subset(test1, select=-c(times,Obs))
x1 <- model.matrix(~., x1)
x1.test <-model.matrix(~., x1.test)
library(doParallel)
registerDoParallel(4)
set.seed(2016)
cv.lasso1 <- cv.glmnet(x=x1,y=y1,family="poisson",alpha=1,nfolds=10,parallel=TRUE)
prediction.lasso1 <- predict(cv.lasso1,as.matrix(x1.test),type="response",s="lambda.min")
mse.min1 <- cv.lasso1$cvm[cv.lasso1$lambda == cv.lasso1$lambda.min]
rmse.lasso1 <- sqrt(mean((y1.test-prediction.lasso1)^2))
mae.lasso1 <- mean(abs(y1.test-prediction.lasso1))
dawiderror <- mean((y1.test-prediction.lasso1)^2/prediction.lasso1 + log(prediction.lasso1))



##bird
bird <- bird %>% subset(select=-c(ten)) %>% subset(select=-c(ten))
sample.size2 <- floor(0.85*max(as.numeric(bird$times)))
set.seed(2016)
train_id2 <- sample(seq_len(max(as.numeric(bird$times))),size=sample.size2)
train2 <- bird[bird$times %in% train_id2,]
test2 <- bird[!bird$times %in% train_id2,]
x2 <- subset(train2, select=-c(times,Obs))
y2 <- as.matrix(subset(train2, select=Obs))
y2.test <- as.matrix(subset(test2, select=Obs))
x2.test <- subset(test2, select=-c(times,Obs))
x2 <- model.matrix(~., x2)
x2.test <-model.matrix(~., x2.test)
library(doParallel)
registerDoParallel(4)
set.seed(2016)
cv.lasso2 <- cv.glmnet(x=x2,y=y2,family="poisson",alpha=1,nfolds=10,parallel=TRUE)
prediction.lasso2 <- predict(cv.lasso2,as.matrix(x2.test),type="response",s="lambda.min")
mse.min2 <- cv.lasso2$cvm[cv.lasso2$lambda == cv.lasso2$lambda.min]
rmse.lasso2 <- sqrt(mean((y2.test-prediction.lasso2)^2))
mae.lasso2 <- mean(abs(y2.test-prediction.lasso2))



## dframe
sample.size3 <- floor(0.85*max(as.numeric(dframe$times)))
set.seed(2016)
train_id3 <- sample(seq_len(max(as.numeric(dframe$times))),size=sample.size3)
train3 <- dframe[dframe$times %in% train_id3,]
test3 <- dframe[!dframe$times %in% train_id3,]
x3 <- subset(train3, select=-c(times,Obs))
y3 <- as.matrix(subset(train3, select=Obs))
y3.test <- as.matrix(subset(test3, select=Obs))
x3.test <- subset(test3, select=-c(times,Obs))
x3 <- model.matrix(~., x3)
x3.test <-model.matrix(~., x3.test)
library(doParallel)
registerDoParallel(4)
set.seed(2016)
cv.lasso3 <- cv.glmnet(x=x3,y=y3,family="poisson",alpha=1,nfolds=10,parallel=TRUE)
prediction.lasso3 <- predict(cv.lasso3,as.matrix(x3.test),type="response",s="lambda.min")
mse.min3 <- cv.lasso3$cvm[cv.lasso3$lambda == cv.lasso3$lambda.min]
rmse.lasso3 <- sqrt(mean((y3.test-prediction.lasso3)^2))
mae.lasso3 <- mean(abs(y3.test-prediction.lasso3))


### group lasso

#group lasso ### didn't show better
group <- c(1,rep(2,7),rep(3,45),4,5,rep(6,11),rep(7,45),rep(8,45),rep(9,45),rep(10,45),rep(11,45),rep(12,45),rep(13,45),rep(14,45))
cv.glasso <- cv.grpreg(X=x1,y=y1,family="poisso",penalty="grLasso",group,nfolds=10,parallel=TRUE,seed=2016)
prediction.glasso <- predict(cv.glasso,as.matrix(x1.test),type="response")
rmse.glasso <- sqrt(mean((y1.test-prediction.glasso)^2))
mae.glasso <- mean(abs(y1.test-prediction.glasso))



### adaptive lasso
set.seed(2016)
library(doParallel)
registerDoParallel(4)
betals <- solve(t(x1)%*%x1)%*%t(x1)%*%y1
cv.adapl <- cv.glmnet(x=x1,y=y1,family="poisson",alpha=1,nfolds=10,penalty.factor=1/abs(betals),parallel=TRUE)
minlam.adapl <- cv.adapl$lambda.min
mse.min <- cv.adapl$cvm[cv.adapl$lambda == cv.adapl$lambda.min]
prediction.adapl <- predict(cv.adapl,as.matrix(x1.test),type="response",s="lambda.min")
rmse.adapl <- sqrt(mean((y1.test-prediction.adapl)^2))
mae.adapl <- mean(abs(y1.test-prediction.adapl))



##test negative binomial
library(mpath)
cv.test <- cv.glmreg_fit(x1.nb, y1.nb, family="negbin",nfolds=5,alpha=1,theta=1,n.cores=4)
prediction.nb <- predict(cv.test,as.matrix(x1.test),type="response",s="lambda.optim")

prediction.nb <- predict(object=cv.test$fit, which=cv.test$lambda.which, type="response",
                         model=c("full"))




### average mass prediction 

attribute.mass <- attribute %>% subset(select=c(location,timestep,peak_mass))
names(attribute.mass) <- c("location","times","peakmass")
birds.mass <- birds %>% subset(select=-c(Obs)) %>% join(attribute.mass,by=c("times","location"),type="left")
birds.mass[is.na(birds.mass)] <- 0
write.csv(birds.mass,file="birds_mass.csv",row.names=FALSE)

samplesize.mass <- floor(0.85*max(as.numeric(birds.mass$times)))
set.seed(2016)
train_id <- sample(seq_len(max(as.numeric(birds.mass$times))),size=samplesize.mass)
train <- birds.mass[birds.mass$times %in% train_id,]
test <- birds.mass[!birds.mass$times %in% train_id,]
x.mass <- train[,c(-1,-421)]
y.mass <- train[,421]
y.test.mass <- test[,421]
x.test.mass <- test[,c(-1,-421)]
x.mass <- model.matrix(~., x.mass)
x.test.mass <-model.matrix(~., x.test.mass)
library(doParallel)
registerDoParallel(4)
set.seed(2016)
cv.lasso.mass <- cv.glmnet(x=x.mass,y=y.mass,family="gaussian",alpha=1,nfolds=5,parallel=TRUE)
prediction.lasso.mass <- predict(cv.lasso.mass,as.matrix(x.test.mass),type="response",s="lambda.min")
mse.min.mass <- cv.lasso.mass$cvm[cv.lasso.mass$lambda == cv.lasso.mass$lambda.min]
rmse.lasso.mass <- sqrt(mean((y.test.mass-prediction.lasso.mass)^2))
mae.lasso.mass <- mean(abs(y.test.mass-prediction.lasso.mass))

#group lasso
group <- c(rep(1,8),rep(2,45),3,4,rep(5,11),rep(6,360))
cv.glasso <- cv.grpreg(X=x.mass,y=y.mass,family="gaussian",penalty="grLasso",group,nfolds=5,parallel=TRUE,seed=2016)
prediction.glasso <- predict(cv.glasso,as.matrix(x.test.mass),type="response")
rmse.glasso <- sqrt(mean((y.test.mass-prediction.glasso)^2))
mae.glasso <- mean(abs(y.test.mass-prediction.glasso))
#result almost same with lasoo


set.seed(2016)
library(doParallel)
registerDoParallel(4)
cv.ridge <- cv.glmnet(x=x.mass,y=y.mass,family="gaussian",alpha=0,nfolds=5,parallel=TRUE)
minlam.ridge <- cv.ridge$lambda.min
mse.min <- cv.ridge$cvm[cv.ridge$lambda == cv.ridge$lambda.min]
#prediction error
prediction.ridge <- predict(cv.ridge,as.matrix(x.test.mass),type="response",s="lambda.min")
rmse.ridge <- sqrt(mean((y.test.mass-prediction.ridge)^2))
mae.ridge <- mean(abs(y.test.mass-prediction.ridge))

set.seed(2016)
library(doParallel)
registerDoParallel(4)
cv.elastic <- cv.glmnet(x.mass,y.mass,family="gaussian",alpha=0.5,nfolds=5,parallel=TRUE)
minlam.elastic <- cv.elastic$lambda.min
mse.min <- cv.elastic$cvm[cv.elastic$lambda == cv.elastic$lambda.min]
#prediction error
prediction.elastic <- predict(cv.elastic,as.matrix(x.test.mass),type="response",s="lambda.min")
rmse.elastic <- sqrt(mean((y.test.mass-prediction.elastic)^2))
mae.elastic <- mean(abs(y.test.mass-prediction.elastic))

set.seed(2016)
library(doParallel)
registerDoParallel(4)
betals <- solve(t(x.mass)%*%x.mass)%*%t(x.mass)%*%y.mass
cv.adapl <- cv.glmnet(x.mass,y.mass,family="gaussian",alpha=0.5,nfolds=5,penalty.factor=1/abs(betals),parallel=TRUE)
minlam.adapl <- cv.adapl$lambda.min
mse.min <- cv.adapl$cvm[cv.adapl$lambda == cv.adapl$lambda.min]
#prediction error
prediction.adapl <- predict(cv.adapl,as.matrix(x.test.mass),type="response",s="lambda.min")
rmse.adapl <- sqrt(mean((y.test.mass-prediction.adapl)^2))
mae.adapl <- mean(abs(y.test.mass-prediction.adapl))

library(ncvreg)
set.seed(2016)
library(doParallel)
registerDoParallel(4)
cv.mcp <- cv.ncvreg(X=x.mass,y=y.mass,family="gaussian",penalty="MCP",nfolds=5,parallel=TRUE)
minlam.mcp <- cv.mcp$lambda.min
mse.min <- min(cv.mcp$cve)
#prediction error
prediction.mcp <- predict(cv.mcp,as.matrix(x.test.mass),type="response",lambda=minlam.mcp)
rmse.mcp <- sqrt(mean((y.test.mass-prediction.mcp)^2))
mae.mcp <- mean(abs(y.test.mass-prediction.mcp))

set.seed(2016)
library(doParallel)
registerDoParallel(4)
cv.scad <- cv.ncvreg(X=x.mass,y=y.mass,family="gaussian",penalty="SCAD",nfolds=5,parallel=TRUE)
minlam.scad <- cv.scad$lambda.min
mse.min <- min(cv.scad$cve)
#prediction error
prediction.scad <- predict(cv.scad,as.matrix(x.test),type="response",lambda=minlam.scad)
rmse.scad <- sqrt(mean((y.test-prediction.scad)^2))
mae.scad <- mean(abs(y.test-prediction.scad))


## neural networks 
# all features
library(neuralnet)
samplesize.mass <- floor(0.85*max(as.numeric(birds.mass$times)))
set.seed(2016)
train_id <- sample(seq_len(max(as.numeric(birds.mass$times))),size=samplesize.mass)
mass.train <- birds.mass[birds.mass$times %in% train_id,]
mass.test <- birds.mass[!birds.mass$times %in% train_id,]
x.mass <- mass.train[,-1]
y.mass <- mass.train[,421]
y.test.mass <- mass.test[,421]
x.test.mass <- mass.test[,c(-1,-421)]
x.mass <- model.matrix(~., x.mass)
x.test.mass <-model.matrix(~., x.test.mass)
n <- colnames(x.mass)[-1]
f <- as.formula(paste('peakmass ~', paste(n[!n %in% 'peakmass'], collapse = ' + ')))


nn <- neuralnet(f,data=x.mass[,-1],hidden=c(180,60,30,6),linear.output=TRUE,threshold = 0.1,lifesign = "minimal")

pr.nn <- compute(nn,x.test.mass[,-1])$net.result
RMSE.nn <- sqrt(mean((y.test.mass-pr.nn)^2))






# cv for nn
attribute.mass <- attribute %>% subset(select=c(location,timestep,peak_mass))
names(attribute.mass) <- c("location","times","peakmass")
birds.mass <- birds %>% subset(select=-c(Obs)) %>% join(attribute.mass,by=c("times","location"),type="left")
birds.mass[is.na(birds.mass)] <- 0
# all features to class
birdsmass <-birds.mass %>% mutate(peakmass=cut(birds.mass$peakmass,
                                             breaks=c(0,round(median(birds.mass$peakmass)),
                                                      ceiling(max(birds.mass$peakmass))),
                                             right = FALSE,labels=c(0,1))) 

#h2O for NN classification
folds <- data.frame(times=seq(1:max(as.numeric(birdsmass$times))),
                    folds=cut(seq(1:max(as.numeric(birdsmass$times))),
                              breaks=20,labels=seq(1:20)))
birds.h2o <- join(birdsmass,folds,by="times")
perform <-performance  <- rate <-  NULL
models <- hidden <- predictions <-  list()
library(h2o)
h2o.init(max_mem_size = "8g",nthreads = -1)
for (j in 1:1){
  rand_hidden <- c(sample(1:200,8,T))
  for (i in 0:8){
  train <-  birds.h2o[birds.h2o$folds %in% c(1:10+i),]
  valid <-  birds.h2o[birds.h2o$folds %in% c(i+11),]
  birds.dl <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(train),
                               activation="Tanh",hidden=rand_hidden,
                               distribution = "bernoulli",
                               loss ="CrossEntropy",validation_frame=as.h2o(valid),l2=1e-05)
  perform[i] <- h2o.logloss(birds.dl, valid=T) 
  }
  performance[j] <- mean(perform)
  hidden[j] <-  as.data.frame(rand_hidden)
  models[j] <-  birds.dl
  birds.class <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(birds.h2o[birds.h2o$folds %in% c(1:19),]),
                                  activation="Tanh",hidden=rand_hidden,
                                  distribution = "bernoulli",
                                  loss ="CrossEntropy",l2=1e-05)
  predictions <- h2o.predict(birds.class, as.h2o(birds.h2o[birds.h2o$folds %in% c(20),]))
  table <- table(birds.h2o[birds.h2o$folds %in% c(20),][,420],as.data.frame(predictions$predict)[,1])
  rate[j] <- sum(diag(table))/sum(table)
}
h2o.shutdown()


#h2o for penalized

folds <- data.frame(times=seq(1:max(as.numeric(birds.mass$times))),
                    folds=cut(seq(1:max(as.numeric(birds.mass$times))),
                              breaks=20,labels=seq(1:20)))
birds.pv <- join(birds.mass,folds,by="times")
alpha_opts <-  c(0,0.25,0.5,0.75,1)
h2o.init(max_mem_size = "16g",nthreads = -1)
rmse <-  perform <-performance  <-  NULL
models <- list()
for (j in 1:5){
  hyper_parameters <-  alpha_opts[j]
for (i in 0:8){
  train <-  birds.pv[birds.pv$folds %in% c(1:10+i),]
  valid <-  birds.pv[birds.pv$folds %in% c(i+11),]
  birds.models <- h2o.glm(x = 2:419, y = 420, training_frame = as.h2o(train),
                      family = "gaussian",lambda_search = T,nlambdas=100,
                      validation_frame=as.h2o(valid),standardize=TRUE,
                      alpha = hyper_parameters)
  rmse[i] <- sqrt(h2o.mse(birds.models,valid = TRUE))
}
  models[j] <-  birds.models
  performance[j] <- mean(rmse)
}
birds.class <- h2o.glm(x = 2:419, y = 420, training_frame = as.h2o(birds.pv[birds.pv$folds %in% c(1:19),]),
                       family = "gaussian",lambda = 0.004839,alpha=1,standardize=TRUE)
predictions <- h2o.predict(birds.class, as.h2o(birds.pv[birds.pv$folds %in% c(20),]))
RMSE <- sqrt(mean((birds.pv[birds.pv$folds %in% c(20),][,420] - as.data.frame(predictions$predict)[,1])^2))
MAE <- mean(abs(birds.pv[birds.pv$folds %in% c(20),][,420] - as.data.frame(predictions$predict)[,1]))



#h2O for NN regression

folds <- data.frame(times=seq(1:max(as.numeric(birds.mass$times))),
                    folds=cut(seq(1:max(as.numeric(birds.mass$times))),
                              breaks=10,labels=seq(1:10)))
birds.pv <- join(birds.mass,folds,by="times")
h2o.init(max_mem_size = "8g")
perform <-performance <-  NULL
models <- list()
for (j in 1:2){
  rand_activation <- c("Rectifier", "RectifierWithDropout")[sample(1:2,1)]
  rand_hidden <- c(sample(10:150,3,T))
  for (i in 1:8){
    train <-  birds.pv[birds.pv$folds %in% c(1:i),]
    valid <-  birds.pv[birds.pv$folds %in% c(i+1),]
    birds.dl <- h2o.deeplearning(x = 2:420, y = 421, training_frame = as.h2o(train),
                                 activation=rand_activation,hidden=rand_hidden,
                                 distribution ="gaussian",
                                 epochs=0.1,loss ="Quadratic",validation_frame=as.h2o(valid),
                                 l1=1e-05)
    perform[i] <- sqrt(h2o.mse(birds.dl, valid=T)) 
  }
  models[j] <-  birds.dl
  performance[j] <- mean(perform)
}






#--------------------------------#
# comparison test
birdsmass <-birds.mass %>% mutate(peakmass=cut(birds.mass$peakmass,
                                               breaks=c(0,round(median(birds.mass$peakmass)),
                                                        ceiling(max(birds.mass$peakmass))),
                                               right = FALSE,labels=c(0,1))) 
folds <- data.frame(times=seq(1:max(as.numeric(birdsmass$times))),
                    folds=cut(seq(1:max(as.numeric(birdsmass$times))),
                              breaks=20,labels=seq(1:20)))
birds.h2o <- join(birdsmass,folds,by="times")
folds <- data.frame(times=seq(1:max(as.numeric(birds.mass$times))),
                    folds=cut(seq(1:max(as.numeric(birds.mass$times))),
                              breaks=20,labels=seq(1:20)))
birds.pv <- join(birds.mass,folds,by="times")

perform <-performance <- models <- perform.rg <- perform.cl <-  NULL
library(h2o)
h2o.init(max_mem_size = "8g",nthreads = -1)
  for (i in 0:8){
    train.cl <-  birds.h2o[birds.h2o$folds %in% c(1:10+i),]
    valid.cl <-  birds.h2o[birds.h2o$folds %in% c(i+11),]
    train.rg <-  birds.pv[birds.pv$folds %in% c(1:10+i),]
    valid.rg <-  birds.pv[birds.pv$folds %in% c(i+11),]
    birds.cl <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(train.cl),
                                 activation="Tanh",hidden=c(200,120,30),
                                 distribution = "bernoulli",
                                 loss ="CrossEntropy",validation_frame=as.h2o(valid.cl),l1=1e-05)
    birds.rg <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(train.rg),
                                 activation="Rectifier",hidden=c(200,120,30),
                                 distribution ="gaussian",
                                 loss ="Quadratic",validation_frame=as.h2o(valid.rg),
                                 l1=1e-05)
    perform.rg[i] <- sqrt(h2o.mse(birds.rg, valid=T)) 
    perform.cl[i] <- h2o.logloss(birds.cl, valid=T) 
  }
birds.cl <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(birds.h2o[birds.h2o$folds %in% c(1:19),]),
                                activation="Tanh",hidden=c(127,180,10),
                                distribution = "bernoulli",epochs = 1000,
                                loss ="CrossEntropy")
birds.rg <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(birds.pv[birds.pv$folds %in% c(1:19),]),
                             activation="Rectifier",hidden=c(127,180,10),
                             distribution ="gaussian",
                             loss ="Quadratic",l1=1e-05,epochs = 1000)
predictions.cl <- h2o.predict(birds.cl, as.h2o(birds.h2o[birds.h2o$folds %in% c(20),]))
predictions.rg <- h2o.predict(birds.rg, as.h2o(birds.pv[birds.pv$folds %in% c(20),]))
predictions.rg$predict[predictions.rg$predict < 0] <- 0
RMSE <- sqrt(mean((birds.pv[birds.pv$folds %in% c(20),][,420] - as.data.frame(predictions.rg$predict)[,1])^2))
MAE <- mean(abs(birds.pv[birds.pv$folds %in% c(20),][,420] - as.data.frame(predictions.rg$predict)[,1]))

table1 <- table(birds.h2o[birds.h2o$folds %in% c(20),][,420],as.data.frame(predictions.cl$predict)[,1])
sum(diag(table1))/sum(table1)

median <- round(median(birds.mass$peakmass))
max <- ceiling(max(birds.mass$peakmass))
cut1 <- cut(as.numeric(as.data.frame(birds.h2o[birds.h2o$folds %in% c(20),][,420])[,1]),breaks=c(0,median,max),right = FALSE,labels=c(0,1))
cut2 <- cut(as.data.frame(predictions.rg)[,1],breaks=c(0,median,max),right = FALSE,labels=c(0,1))
table2 <- table(cut1,cut2)
sum(diag(table2))/sum(table2)

#ROC curve
birds.cl <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(birds.h2o[birds.h2o$folds %in% c(1:19),]),
                             activation="Tanh",hidden=c(52,177,57),
                             distribution = "bernoulli",epochs = 1000,
                             loss ="CrossEntropy")
predictions.cl <- h2o.predict(birds.cl, as.h2o(birds.h2o[birds.h2o$folds %in% c(20),]))
t <- birds.h2o[birds.h2o$folds %in% c(20),][,420]
toutput <- cbind(as.data.frame(t),as.data.frame(predictions.cl))
write.csv(toutput, file="5217757.csv",row.names=FALSE)


h2o.shutdown()


# prediction plot
t1 <- birds.h2o[birds.h2o$folds %in% c(20),][,c(1,2,420)]
t3 <- birds.pv[birds.pv$folds %in% c(20),][,420]
t2 <- cbind(as.data.frame(t1),as.data.frame(predictions.rg),t3)
t2 <- t2[order(t2$times),]
write.csv(t2,file="t3.csv",row.names=FALSE)


l_lon <-  4.706
r_lat <-  52.368
r_lon <-  4.717
l_lat <-  52.325
lat_det <-  2/111
lon_det <-  2/(cos(r_lat*pi/180)*111.321)
bound_x <-  c(l_lon-lon_det,l_lat-lat_det)
bound_y <-  c(r_lon+lon_det,r_lat+lat_det)
gridx <- seq(l_lon-lon_det,r_lon+lon_det,length.out=4)
gridy <- seq(l_lat-lat_det,r_lat+lat_det,length.out=6)
grid <- expand.grid(x = gridx, y = gridy)
grid$XX <- rep(1:4, times=6)
grid$YY <- rep(1:6, each=4)
grid$location <-  paste("loc",grid$XX, grid$YY, sep="")
library(ggplot2)
library(ggmap)
for (i in 42409:42414){
  heatmapdata <- t2[t2$times %in% c(i),c(1,2,6)]
  joinmap <- join(heatmapdata,grid,by="location")[,c(3,4,5)]
  names(joinmap) <- c('massprob', 'long', 'lat')
  map <- qmap(location = '241CN', zoom = 12) 
  map <- map + geom_tile(data = joinmap, aes(x = long, y = lat, alpha = massprob),fill='blue') + theme(axis.title.y = element_blank(), axis.title.x = element_blank())
  ggsave(paste('',i, 'predict.png', sep=""), map)
}


# best L2 # long time not recommend

#h2O for NN classification
folds <- data.frame(times=seq(1:max(as.numeric(birdsmass$times))),
                    folds=cut(seq(1:max(as.numeric(birdsmass$times))),
                              breaks=20,labels=seq(1:20)))
birds.h2o <- join(birdsmass,folds,by="times")
perform <-performance  <- rate <-  NULL
models <- hidden <- predictions <-  list()
library(h2o)
h2o.init(max_mem_size = "8g",nthreads = -1)
l2 <- seq(0.01,1,0.04)
rand_hidden <- c(69,171,154,179,57)
for (j in 1:length(l2)){
  for (i in 0:8){
    train <-  birds.h2o[birds.h2o$folds %in% c(1:10+i),]
    valid <-  birds.h2o[birds.h2o$folds %in% c(i+11),]
    birds.dl <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(train),
                                 activation="Tanh",hidden=rand_hidden,
                                 distribution = "bernoulli",
                                 loss ="CrossEntropy",validation_frame=as.h2o(valid),l2=l2[j])
    perform[i] <- h2o.logloss(birds.dl, valid=T) 
  }
  performance[j] <- mean(perform)
  hidden[j] <-  as.data.frame(rand_hidden)
  models[j] <-  birds.dl
  birds.class <- h2o.deeplearning(x = 2:419, y = 420, training_frame = as.h2o(birds.h2o[birds.h2o$folds %in% c(1:19),]),
                                  activation="Tanh",hidden=rand_hidden,
                                  distribution = "bernoulli",
                                  loss ="CrossEntropy",l2=l2[j])
  predictions <- h2o.predict(birds.class, as.h2o(birds.h2o[birds.h2o$folds %in% c(20),]))
  table <- table(birds.h2o[birds.h2o$folds %in% c(20),][,420],as.data.frame(predictions$predict)[,1])
  rate[j] <- sum(diag(table))/sum(table)
}



#------------#
#SVM#
# cv for nn
attribute.mass <- attribute %>% subset(select=c(location,timestep,peak_mass))
names(attribute.mass) <- c("location","times","peakmass")
birds.mass <- birds %>% subset(select=-c(Obs)) %>% join(attribute.mass,by=c("times","location"),type="left")
birds.mass[is.na(birds.mass)] <- 0
# all features to class
birdsmass <-birds.mass %>% mutate(peakmass=cut(birds.mass$peakmass,
                                               breaks=c(0,round(median(birds.mass$peakmass)),
                                                        ceiling(max(birds.mass$peakmass))),
                                               right = FALSE,labels=c(0,1))) 

#h2O for NN classification
folds <- data.frame(times=seq(1:max(as.numeric(birdsmass$times))),
                    folds=cut(seq(1:max(as.numeric(birdsmass$times))),
                              breaks=20,labels=seq(1:20)))
birds.svm <- join(birdsmass,folds,by="times")[,-1]
cost <- 10^(-1:2)
gamma <- c(0.5,1)
epsilon <- seq(0.5,1,0.1)
par <- expand.grid(cost,gamma,epsilon)


eval <- function(j){
  rate <- NULL
  for (i in 0:8){
    library(e1071)
    train <-  birds.svm[birds.svm$folds %in% c(1:10+i),-ncol(birds.svm)]
    valid <-  birds.svm[birds.svm$folds %in% c(i+11),-which(names(birds.svm) %in% c("peakmass","folds"))]
    birds.svm <- svm(peakmass~.,data=train,cost=par[j,1],gamma=par[j,2],epsilon=par[j,3])
    predicted <- predict(birds.svm,data=valid)
    table <- table(predicted ,valid$peakmass)
    rate <- cbind(rate,sum(diag(table))/sum(table))
  }
  mean(rate)
}
library(doParallel)
registerDoParallel()
getDoParWorkers()
pr <- foreach(j=1:length(par),.combine=list)%dopar%eval(j)
